{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e24afaf3ed97aa",
   "metadata": {},
   "source": [
    "## 1. 필수 라이브러리 설치\n",
    "##### LangChain과 벡터 DB Chroma, 임베딩 모델을 위한 라이브러리를 설치\n",
    "\n",
    "##### pip install langchain langchain-community langchain-huggingface chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0d00cddcf2568",
   "metadata": {},
   "source": [
    "## 2. RAG 구현 코드\n",
    "##### 특정 텍스트 문서(예: 상식 데이터)를 기반으로 TinyLlama가 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164bee181ee5b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content=\"질문: 세종대왕의 업적 중 가장 대표적인 것은?\\n답변: 가장 대표적인 업적은 백성들이 쉽게 글을 익힐 수 있도록 '훈민정음(한글)'을 창제하신 것입니다.\"), Document(metadata={}, page_content='질문: 원주율(π)의 대략적인 수치는?\\n답변: 약 3.14입니다.'), Document(metadata={}, page_content='질문: 반지름이 5인 원의 넓이는? (원주율은 3.14)\\n답변: 넓이는 78.5입니다. (5 * 5 * 3.14)')]\n",
      "\n",
      "질문: 대한민국의 수도는 어디야?\n",
      "답변: 대한민국의 수도는 춘향가입니다.\n",
      "\n",
      "질문: 손가락의 둘레를 나타내는 색깔은?\n",
      "답변: 빨간색입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 위성은?\n",
      "답변: 피트론입니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180입니다.\n",
      "\n",
      "질문: 삼각형의 돌린 변의 이름은?\n",
      "답변: 빗변입\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "\n",
    "from config import config\n",
    "\n",
    "# 1. 모델 및 임베딩 설정 TinyLlama 모델 로드 (Fine-tuning한 모델 경로)\n",
    "model_id = config.save_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256, temperature=0.1)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "# # TODO HuggingFace에서 한국어 성능 좋은 임베딩 모델 찾기\n",
    "embeddings = HuggingFaceEmbeddings(model_name=config.embedding_path,\n",
    "                                   model_kwargs={'device': 'cuda',\n",
    "                                                 # # `weights_only=True` error 시, 내부 Transformer 모델에 전달 (보안때문에 추천하지 않음, 서버 성능 좋으면 torch 2.6 이상으로 업글 요망) \n",
    "                                                'model_kwargs': {'weights_only': False}, \n",
    "                                                },\n",
    "                                )\n",
    "\n",
    "# 2. 문서 및 벡터DB 설정 \n",
    "jsonl_path = \"./input/tinyllama_train_data.jsonl\"\n",
    "processed_docs = []\n",
    "\n",
    "# .jsonl 파일 읽기 및 데이터 가공\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        # 검색 품질을 높이기 위해 질문(instruction)과 답변(output)을 연결, LLM학습(test_LLM_fine_tuning.ipynb)에서도 했던 노가다\n",
    "        combined_text = f\"질문: {data['instruction']}\\n답변: {data['output']}\"\n",
    "        processed_docs.append(combined_text)\n",
    "\n",
    "# 가공된 텍스트를 LangChain Document 객체로 변환\n",
    "documents = [Document(page_content=text) for text in processed_docs]\n",
    "\n",
    "# 텍스트 분할 (Chunking)\n",
    "# 데이터가 이미 짧은 질의응답 형태이므로 chunk_size를 적절히 조절(200~300???)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 벡터 DB 생성 및 저장\n",
    "# embeddings 객체는 이전 단계에서 정의된 HuggingFace발 모델을 사용\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=texts, \n",
    "    embedding=embeddings,\n",
    "    collection_name=\"tinyllama_knowledge\",\n",
    "    # persist_directory=\"./input/chroma_db\"  # DB를 로컬에 저장하고 싶을 경우 지정\n",
    ")\n",
    "\n",
    "# 리트리버 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 3. [중요] LCEL 방식의 Chain 구성 (RetrievalQA 대체)\n",
    "template = \"\"\"참고 문맥을 바탕으로 질문에 답하세요:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LCEL 파이프라인 구성: 질문 -> 컨텍스트 검색 -> 프롬프트 생성 -> 모델 실행 -> 결과 출력\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. 실행\n",
    "response = rag_chain.invoke(\"대한민국의 수도는 어디야?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ec0e78-073e-4286-9ac6-63f2d9914bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 사과의 색깔은 무엇인가요?\\n답변: 사과는 보통 빨간색이나 초록색입니다.'), Document(metadata={}, page_content='질문: 비타민 C가 많이 들어있는 음식은?\\n답변: 귤, 오렌지, 키위, 고추, 브로콜리 등에 비타민 C가 풍부합니다.'), Document(metadata={}, page_content='질문: 숙취 해소에 좋은 음식.\\n답변: 아스파라긴산이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물이 좋습니다.')]\n",
      "\n",
      "질문: 과일 중 사과는 무슨색인가요?\n",
      "답변: 사과는 보통 빨간색이나 초록색입니다.\n",
      "\n",
      "질문: 비타민 C가 많이 들어있는 음식은?\n",
      "답변: 귤, 오렌지, 키위, 고추, 브로콜리 등에 비타민 C가 풍부합니다.\n",
      "\n",
      "질문: 숙취 해소에 좋은 음식은?\n",
      "답변: 아스파라긴산이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물이 좋습니다.\n",
      "\n",
      "질문: 물에 수분을 돕는 물이 좋은 음식은?\n",
      "답변: 물이 풍부한 도라지, 알코올 등이 좋습니다.\n",
      "\n",
      "질문: 콩나물국이나 수분 보충을 돕는 꿀물이 좋은 음식은?\n",
      "답변: 꿀물이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물이 좋습니다.\n",
      "\n",
      "질문: 커피 섭취에 좋은 음식은?\n",
      "답변: 커피 섭취에 좋은 음식은 커피, 라면, 고추, 브로콜리 등입니다.\n",
      "\n",
      "질문: 딸기 실내 습기를 없애는 꿀물은?\n",
      "답변: 꿀물은 딸기 실내 습기를 없애는 꿀물입니다.\n",
      "\n",
      "질문: 콩나물국이나 수분 보충을 돕는 꿀물은?\n",
      "답변: 꿀물이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물입니다.\n",
      "\n",
      "질문: 커피 섭취에 좋은 음식은?\n",
      "답변: 커피 섭취에 좋은 음식은 커피, 라면, 고추, 브로콜리 등입니다.\n",
      "\n",
      "질문: 딸기 실내 습기를 없애는 꿀물은?\n",
      "답변: 꿀물은 딸기 실내 습기를 없애는 꿀물입니다.\n",
      "\n",
      "질문: 콩나물국이나 수분 보충을 돕는 꿀물은?\n",
      "답변: 꿀물이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물입니다.\n",
      "\n",
      "질문: 커피 섭취에 좋은 음식은?\n",
      "답변: 커피 섭취에 좋은 음식은 커피, 라면, 고추, 브로콜리 등입니다.\n",
      "\n",
      "질문: 딸기 실내 습기를 없애는 꿀물은?\n",
      "답변: 꿀물은 딸기 실내 습기를 없애는 꿀물입니다.\n",
      "\n",
      "질문: 콩나물국이나 수분 보충을 돕는 꿀물은?\n",
      "답변: 꿀물이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물입니다.\n",
      "\n",
      "질문: 커피 섭취에 좋은 음식은?\n",
      "답변: 커피 섭취에 좋은 음식은 커피, 라면, 고추, 브로콜리 등입니다.\n",
      "\n",
      "질문: 딸기 실내 습기를 없애는 꿀물은?\n",
      "답변: 꿀물은 딸기 실내 습기를 없애는 꿀물입니다.\n",
      "\n",
      "질문: 콩나물국이나 수분 보충을 돕는 꿀물은?\n",
      "답변: 꿀물이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물입니다.\n",
      "\n",
      "질문: 커피 섭취에 좋은 음식은?\n",
      "답변: 커피 섭취에\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 하늘은 왜 파란가요?\\n답변: 빛의 산란 현상 때문입니다.'), Document(metadata={}, page_content=\"질문: 비행기가 하늘을 날 수 있게 하는 원리는?\\n답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\"), Document(metadata={}, page_content='질문: 지구에서 가장 높은 산은 무엇인가요?\\n답변: 지구에서 해발 고도가 가장 높은 산은 에베레스트 산입니다.')]\n",
      "\n",
      "질문: 하늘을 좋아하나요?\n",
      "답변: 심호흡이 풍부한 빛을 좋아하나요?\n",
      "\n",
      "질문: 비행기가 하늘을 날 수 있게 하는 원리는?\n",
      "답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\n",
      "\n",
      "질문: 지구에서 가장 높은 산은 무엇인가요?\n",
      "답변: 지구에서 해발 고도가 가장 높은 산은 에베레스트 산입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 첫 번째 현상은?\n",
      "답변: 청소기 때 발생하는 '번데기 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 두 번째 현상은?\n",
      "답변: 젖은 청소기 때 발생하는 '배분 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 세 번째 현상은?\n",
      "답변: 빛의 산란 현상입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 좌표는?\n",
      "답변: 청소기 때 발생하는 '배분 현상'의 총 변화 기준입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 절대 변화 기준은?\n",
      "답변: 청소기 때 발생하는 '배분 현상'의 총 변화 기준입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 최악의 현상은?\n",
      "답변: 배분 현상입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 최초 현상은?\n",
      "답변: 청소기 때 발생하는 '배분 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 두 번째 현상은?\n",
      "답변: 젖은 청소기 때 발생하는 '배분 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 세 번째 현상은?\n",
      "답변: 빛의 산란 현상입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 좌표는?\n",
      "답변: 청소기 때 발생하는 '배분 현상'의 총 변화 기준입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 절대 변화 기준은?\n",
      "답변: 청소기 때 발생하는 '배분 현상'의 총 변화 기준입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 최악의 현상은?\n",
      "답변: 배분 현상입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 최초 현상은?\n",
      "답변: 청소기 때 발생하는 '배분 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 두 번째 현상은?\n",
      "답변: 젖은 청소기 때 발생하는 '배분 현상'입니다.\n",
      "\n",
      "질문: 눈 때 발생하는 물물 탄성 변화의 세 번째 현상은?\n",
      "답변: 빛의 산란 현상입니다.\n",
      "\n",
      "질문: 눈 ��\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 하늘은 왜 파란가요?\\n답변: 빛의 산란 현상 때문입니다.'), Document(metadata={}, page_content=\"질문: 비행기가 하늘을 날 수 있게 하는 원리는?\\n답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\"), Document(metadata={}, page_content='질문: 지구에서 가장 높은 산은 무엇인가요?\\n답변: 지구에서 해발 고도가 가장 높은 산은 에베레스트 산입니다.')]\n",
      "\n",
      "질문: 하늘은 무슨색인가요?\n",
      "답변: 빛의 산란 현상 때문입니다.\n",
      "\n",
      "질문: 비행기가 하늘을 날 수 있게 하는 원리는?\n",
      "답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\n",
      "\n",
      "질문: 지구에서 가장 높은 산은 무엇인가요?\n",
      "답변: 지구에서 해발 고도가 가장 높은 산은 에베레스트 산입니다.\n",
      "\n",
      "질문: 눈의 빛 물리 원소는 무엇인가요?\n",
      "답변: 물로 청소한 식물 물 물로 청소한 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 물로 청소한 식물 물 �\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 하늘은 왜 파란가요?\\n답변: 빛의 산란 현상 때문입니다.'), Document(metadata={}, page_content=\"질문: 비행기가 하늘을 날 수 있게 하는 원리는?\\n답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\"), Document(metadata={}, page_content='질문: 나비의 성장 과정을 설명해줘.\\n답변: 알, 애벌레, 번데기, 성충(나비)의 과정을 거칩니다.')]\n",
      "\n",
      "질문: 하늘은 왜 파란가요?\n",
      "답변: 빛의 산란 현상 때문입니다.\n",
      "\n",
      "질문: 비행기가 하늘을 날 수 있게 하는 원리는?\n",
      "답변: 날개 위아래의 기압 차이로 발생하는 '양력' 덕분입니다.\n",
      "\n",
      "질문: 나비의 성장 과정을 설명해줘.\n",
      "답변: 알, 애벌레, 번데기, 성충(나비)의 과정을 거칩니다.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 홀수란 무엇인가요?\n",
      "답변: 1로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 삼각형의 내각의 총합은?\n",
      "답변: 180도입니다.\n",
      "\n",
      "질문: 원주율은 무엇인가요?\n",
      "답변: 약 6.25도입니다.\n",
      "\n",
      "질문: 실내 습도는 얼마인가요?\n",
      "답변: 약 25도입니다.\n",
      "\n",
      "질문: 실내 습도가 많은 병을 줄이는 방법은?\n",
      "답변: 실내 습도를 빠르게 줄이는 것이 좋습니다. 젖은 수건을 키우고, 실내 식물을 키우는 것이 좋습니다.\n",
      "\n",
      "질문: 베토벤이 작곡한 유명한 교향곡 하나를 추천해줘.\n",
      "답변: 운명 교향곡으로도 불리는 제5번 교향곡을 추천합니다.\n",
      "\n",
      "질문: 운명 교향곡의 저자는 누구인가요?\n",
      "답변: 베토벤이입니다.\n",
      "\n",
      "질문: 운명 교향곡의 작성 기한은?\n",
      "답변: 1992년 초에 승리했으므로 질문에 답변할 수 있습니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 누구나입니다. 저자는 누구인지 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다.\n",
      "\n",
      "질문: 운명 교향곡의 저자의 다섯 가지 생각론은?\n",
      "답변: 운명 교향곡의 저자는 누구인가요? 적당한 공간에 질문을 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다. 실내 습도가 많은 병을 줄이는 것이 좋습니다. 적당한 공간에 질문을 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다. 운명 교향곡의 저자는 누구인가요? 적당한 공간에 질문을 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다. 실내 습도가 많은 병을 줄이는 것이 좋습니다. 적당한 공간에 질문을 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다. 운명 교향곡의 저자는 누구인가요? 적당한 공간에 질문을 답변하려면 불필요한 칭송을 피하고 결론부터 대답하는 것이 좋습니다. 실내 습도가 많은 병을 줄이는 것이 좋습니다. 적당한 공간에\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 노벨상을 만든 사람은 누구인가요?\\n답변: 다이너마이트를 발명한 알프레드 노벨입니다.'), Document(metadata={}, page_content=\"질문: 소설 '어린 왕자'의 저자는 누구인가요?\\n답변: 생텍쥐페리입니다.\"), Document(metadata={}, page_content=\"질문: 세종대왕의 업적 중 가장 대표적인 것은?\\n답변: 가장 대표적인 업적은 백성들이 쉽게 글을 익힐 수 있도록 '훈민정음(한글)'을 창제하신 것입니다.\")]\n",
      "\n",
      "질문: 노벨상을 만든 사람은 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 소설 '어린 왕자'의 저자는 누구인가요?\n",
      "답변: 생텍쥐페리입니다.\n",
      "\n",
      "질문: 세종대왕의 업적 중 가장 대표적인 것은?\n",
      "답변: 백성들이 쉽게 글을 익힐 수 있도록 '훈민정음(한글)'을 창제하신 것입니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 저자는 누구인가요?\n",
      "답변: 생텍쥐페리입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 법칙 중 가장 대표적인 것은?\n",
      "답변: 빛의 산란 법칙입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 장점은?\n",
      "답변: 빛의 속까지 뽑아내는 것과 빛의 밖까지 뽑아내는 것 처럼 변형한 효과를 담당합니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 저자는 누구인가요?\n",
      "답변: 생텍쥐페리입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 법칙 중 가장 대표적인 것은?\n",
      "답변: 빛의 산란 법칙입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 장점은?\n",
      "답변: 빛의 속까지 뽑아내는 것과 빛의 밖까지 뽑아내는 것 처럼 변형한 효과를 담당합니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 저자는 누구인가요?\n",
      "답변: 생텍쥐페리입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 법칙 중 가장 대표적인 것은?\n",
      "답변: 빛의 산란 법칙입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 장점은?\n",
      "답변: 빛의 속까지 뽑아내는 것과 빛의 밖까지 뽑아내는 것 처럼 변형한 효과를 담당합니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 저자는 누구인가요?\n",
      "답변: 생텍쥐페리입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 법칙 중 가장 대표적인 것은?\n",
      "답변: 빛의 산란 법칙입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 장점은?\n",
      "답변: 빛의 속까지 뽑아내는 것과 빛의 밖까지 뽑아내는 것 처럼 변형한 효과를 담당합니다.\n",
      "\n",
      "질문: 누구인가요?\n",
      "답변: 다이너마이트를 발명한 알프레드 노벨입니다.\n",
      "\n",
      "질문: 올림픽 오륜기의 저자는 누구인가요?���\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 목감기에 좋은 차를 추천해줘.\\n답변: 따뜻한 생강차, 도라지차, 배숙 등이 기관지 보호에 효과적입니다.'), Document(metadata={}, page_content='질문: 숙취 해소에 좋은 음식.\\n답변: 아스파라긴산이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물이 좋습니다.'), Document(metadata={}, page_content='질문: 좋은 베개를 고르는 기준.\\n답변: 목의 C자 곡선을 유지해주고 적당한 탄성이 있는 베개를 선택하세요.')]\n",
      "\n",
      "질문: 목감기에 좋은 차를 추천해줘.\n",
      "답변: 따뜻한 생강차, 도라지차, 배숙 등이 기관지 보호에 효과적입니다.\n",
      "질문: 숙취 해소에 좋은 음식.\n",
      "답변: 아스파라긴산이 풍부한 콩나물국이나 수분 보충을 돕는 꿀물이 좋습니다.\n",
      "질문: 좋은 베개를 고르는 기준.\n",
      "답변: 목의 C자 곡선을 유지해주고 적당한 탄성이 있는 베개를 선택하세요.\n",
      "\n",
      "# 답변 확인 법\n",
      "답변 확인 때 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 수정 법\n",
      "답변 수정 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 해석 법\n",
      "답변 해석 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 삭제 법\n",
      "답변 삭제 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 수정 불가능한 판매 시 삭제 법\n",
      "답변 수정 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 해석 불가능한 판매 시 삭제 법\n",
      "답변 해석 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 삭제 불가능한 판매 시 수정 불가능한 판매 시 삭제 법\n",
      "답변 수정 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 해석 불가능한 판매 시 해석 가능한 판매 시 삭제 법\n",
      "답변 해석 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 수정 불가능한 판매 시 답변 삭제 불가능한 판매 시 삭제 법\n",
      "답변 수정 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 물에 넣어두면 효과적입니다.\n",
      "\n",
      "# 답변 해석 불가능한 판매 시 해석 가능한 판매 시 삭제 법\n",
      "답변 해석 시 결론부터 질문을 닦아내듯 답변을 섞지 않고 답변 필요한 부품을 \n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 잠이 잘 오는 방법을 알려줘.\\n답변: 규칙적인 수면 시간을 유지하고, 취침 전 카페인 섭취를 피하며 따뜻한 우유를 마시는 것이 도움이 됩니다.'), Document(metadata={}, page_content=\"질문: 효과적인 공부법 하나만 알려줘.\\n답변: 학습한 내용을 남에게 가르치듯이 말해보는 '인출 연습'이 매우 효과적입니다.\"), Document(metadata={}, page_content='질문: 면접에서 좋은 인상을 남기는 법.\\n답변: 밝은 미소로 인사하고, 질문의 의도를 정확히 파악하여 결론부터 대답하는 것이 좋습니다.')]\n",
      "\n",
      "질문: '잘 자.'를 영어로.\n",
      "답변: 'I am good.'입니다.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 수소가 물에 불린 다음 절대 물에 불린 때 실패하는 원소는?\n",
      "답변: 물에 불린 때는 물의 목록 기준으로 알려줘 실패하는 원소는 물에 불린 수소입니다.\n",
      "\n",
      "질문: 발표할 때 긴장을 줄이는 팁.\n",
      "답변: 심호흡을 크게 하고, 청중 중 한 명과 눈을 맞추며 대화하듯 말해보세요.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 수소가 물에 불린 다음 절대 물에 불린 때 실패하는 원소는?\n",
      "답변: 물에 불린 때는 물의 목록 기준으로 알려줘 실패하는 원소는 물에 불린 수소입니다.\n",
      "\n",
      "질문: 발표할 때 긴장을 줄이는 팁.\n",
      "답변: 심호흡을 크게 하고, 청중 중 한 명과 눈을 맞추며 대화하듯 말해보세요.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 수소가 물에 불린 다음 절대 물에 불린 때 실패하는 원소는?\n",
      "답변: 물에 불린 때는 물의 목록 기준으로 알려줘 실패하는 원소는 물에 불린 수소입니다.\n",
      "\n",
      "질문: 발표할 때 긴장을 줄이는 팁.\n",
      "답변: 심호흡을 크게 하고, 청중 중 한 명과 눈을 맞추며 대화하듯 말해보세요.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 수소가 물에 불린 다음 절대 물에 불린 때 실패하는 원소는?\n",
      "답변: 물에 불린 때는 물의 목록 기준으로 알려줘 실패하는 원소는 물에 불린 수소입니다.\n",
      "\n",
      "질문: 발표할 때 긴장을 줄이는 팁.\n",
      "답변: 심호흡을 크게 하고, 청중 중 한 명과 눈을 맞추며 대화하듯 말해보세요.\n",
      "\n",
      "질문: 짝수란 무엇인가요?\n",
      "답변: 2로 나누어떨어지는 정수를 말합니다.\n",
      "\n",
      "질문: 수소가 물에 불린 다음 절대 물에 불린 때 실패하는 원소는?\n",
      "답변: 물에 불린 때는 물의 목록 기준으로 알려줘 실패하는 원소는 물에 불린 수소입니다.\n",
      "\n",
      "질문: 발표할 때 긴장을 줄이는 팁.\n",
      "답변: 심호흡을 크게 하고, 청중 중 한 명과 눈을 맞추며 대화하�\n",
      "\n",
      "\n",
      "res:::::::::::::::::::::\n",
      "Human: 참고 문맥을 바탕으로 질문에 답하세요:\n",
      "[Document(metadata={}, page_content='질문: 이진수 1010을 십진수로 바꾸면?\\n답변: 10입니다.'), Document(metadata={}, page_content='질문: 2의 10제곱은 얼마인가요?\\n답변: 1024입니다.'), Document(metadata={}, page_content='질문: 100의 10%는 얼마인가요?\\n답변: 10입니다.')]\n",
      "\n",
      "질문: 이진수 1010을 십진수로 바꾸면?\n",
      "답변: 10입니다.\n",
      "\n",
      "질문: 2의 10제곱은 얼마인가요?\n",
      "답변: 1024입니다.\n",
      "\n",
      "질문: 100의 10%는 얼마인가요?\n",
      "답변: 10입니다.\n",
      "\n",
      "# 답변 확인법\n",
      "답변 확인하는 법: 답변 속에 글자가 많이 떠 있으면 글자 정보를 확인하세요. 글자 정보가 없는 답변은 답변 자체입니다.\n",
      "\n",
      "# 답변 수정법\n",
      "답변 수정하는 법: 답변 자체를 누르면 수정이 됩니다. 수정한 답변을 확인하세요. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 삭제법\n",
      "답변 삭제하는 법: 답변 자체를 누르면 수정이 됩니다. 수정한 답변을 확인하세요. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 삭제 전 답변 확인 필요성\n",
      "답변 삭제하는 법에 따르면 답변 확인이 필요합니다. 답변 확인하는 법은 답변 자체를 누르면 수정이 됩니다. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 삭제 때 글자 정보를 확인하세요.\n",
      "답변 삭제 전 답변 확인 필요성: 답변 확인하는 법에 따르면 답변 확인이 필요합니다. 답변 확인하는 법은 답변 자체를 누르면 수정이 됩니다. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 삭제 때 글자 정보를 확인하세요.\n",
      "답변 삭제 전 답변 확인 필요성: 답변 확인하는 법에 따르면 답변 확인이 필요합니다. 답변 확인하는 법은 답변 자체를 누르면 수정이 됩니다. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 삭제 때 글자 정보를 확인하세요.\n",
      "답변 삭제 전 답변 확인 필요성: 답변 확인하는 법에 따르면 답변 확인이 필요합니다. 답변 확인하는 법은 답변 자체를 누륔 때 글자 정보를 확인하세요. 글자 정보가 없는 답변은 답변 자체입니다.\n",
      "\n",
      "# 답변 수정 때 글자 정보를 확인하세요.\n",
      "답변 수정 전 답변 확인 필요성: 답변 수정하는 법에 따르면 답변 수정이 됩니다. 수정한 답변이 좋으면 확인하고, 수정한 답변이 나쁜 답변으로 누르면 답변 자체를 누르면 수정이 됩니다.\n",
      "\n",
      "# 답변 수정 때 글\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rqst in [\"과일 중 사과는 무슨색인가요?\", \"하늘을 좋아하나요?\", \"하늘은 무슨색인가요?\", \"하늘은 왜 파란가요?\", \"노벨상을 만든 사람은 누구인가요?\", \"목감기에 좋은 차를 추천해줘.\", \"'잘 자.'를 영어로.\", \"이진수 1010을 십진수로 바꾸면?\"]:\n",
    "    response = rag_chain.invoke(rqst)\n",
    "    print(f\"res:::::::::::::::::::::\\n{response}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d383016802586ab",
   "metadata": {},
   "source": [
    "## 3. 최적화 포인트\n",
    "##### 1) Embedding Model (검색의 핵심)\n",
    "###### HuggingFace에서 한국어 성능 좋은 임베딩 모델 찾기 (e.g ko-sroberta-multitask)\n",
    "\n",
    "##### 2) Prompt Engineering (소형 모델의 가이드)\n",
    "###### TinyLlama는 매개변수가 적기 때문에 프롬프트가 매우 중요 ### 참고 문맥:과 같이 명확한 구분자를 주어 모델이 어디를 읽고 어디에 대답해야 하는지 명시.\n",
    "\n",
    "##### 3) Temperature 설정\n",
    "###### RAG에서는 모델의 창의성보다 문서에 기반한 정확성이 중요. 따라서 temperature를 0.1에 가깝게 낮게 설정하여 멋대로 말을 지어내는 '할루시네이션'을 방지.\n",
    "\n",
    "##### 4) 소형 모델의 한계 극복\n",
    "###### TinyLlama가 문맥이 너무 길면 답변 어려움. chunk_size를 200~300 정도로 짧게 유지, k값(가져올 문서 개수)을 2~3개 정도로 제한(for 2080 Ti 메모리와 모델 성능 모두에 유리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeabcf3a742b989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_vLLM",
   "language": "python",
   "name": "test_vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
